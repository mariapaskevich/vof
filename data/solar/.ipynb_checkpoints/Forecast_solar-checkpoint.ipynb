{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !pip install fbprophet\n",
    "# !pip install xlrd\n",
    "# !pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis\n",
    "import statsmodels.tsa.stattools\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import time\n",
    "from darts import TimeSeries\n",
    "from darts.models import (\n",
    "    FFT,\n",
    "    ExponentialSmoothing,\n",
    "    Theta\n",
    ")\n",
    "from darts.metrics import mape\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from fbprophet import Prophet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 8]\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/district/Actuals.csv')\n",
    "data = data.loc[data.Time<'2020-11-06'] #getting rid of the overlap\n",
    "data.Time = data.Time.astype('datetime64[ns]')\n",
    "data.set_index('Time', inplace=True)\n",
    "\n",
    "data\n",
    "\n",
    "# data_Interim = pd.read_csv('Interim_dataset/Actuals_Interim.csv')\n",
    "# data_Interim['Time'] = data_Interim['Time'].astype('datetime64[ns]')\n",
    "# data_Interim.set_index('Time', inplace=True)\n",
    "\n",
    "# data_Forecast_Interim = pd.read_csv('Interim_dataset/Forecasts_Interim.csv')[['Temperature (C) ','Pressure_kpa',\n",
    "#                        'Cloud Cover (%)','Wind Direction (deg)',\n",
    "#                       'Wind Speed (kmh)','Time']].dropna()\n",
    "\n",
    "# data_Forecast_Interim['Time'] = data_Forecast_Interim['Time'].astype('datetime64[ns]')\n",
    "# data_Forecast_Interim.set_index('Time', inplace=True)\n",
    "\n",
    "# data_Forecast_Interim['Load (kW)'] = data_Interim['Load (kW)']\n",
    "# data_Forecast_Interim.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloudcover_percent = pd.read_excel('data/district/WeatherForecasts/Cloudcover_percent.xlsx', index_col='Time',dtype={'Time':'datetime64[ns]'}, engine='openpyxl')\n",
    "# pressure_kpa = pd.read_excel('data/district/WeatherForecasts/Pressure_kpa.xlsx', index_col='Time',dtype={'Time':'datetime64[ns]'})\n",
    "# temperature_Celcius = pd.read_excel('data/district/WeatherForecasts/Temperature_Celcius.xlsx', index_col='Time',dtype={'Time':'datetime64[ns]'})\n",
    "# winddirection_degree = pd.read_excel('data/district/WeatherForecasts/Winddirection_degree.xlsx', index_col='Time',dtype={'Time':'datetime64[ns]'})\n",
    "# windspeed_kmh = pd.read_excel('data/district/WeatherForecasts/Windspeed_kmh.xlsx', index_col='Time',dtype={'Time':'datetime64[ns]'})\n",
    "\n",
    "# cloudcover_percent.index = cloudcover_percent.index.astype('datetime64[ns]').round('1s')\n",
    "# pressure_kpa.index = pressure_kpa.index.astype('datetime64[ns]').round('1s')\n",
    "# temperature_Celcius.index = temperature_Celcius.index.astype('datetime64[ns]').round('1s')\n",
    "# winddirection_degree.index = winddirection_degree.index.astype('datetime64[ns]').round('1s')\n",
    "# windspeed_kmh.index = windspeed_kmh.index.astype('datetime64[ns]').round('1s')\n",
    "\n",
    "# data['Cloud Cover (%)'] = cloudcover_percent['Cloud Cover (%)']#.astype('datetime64[ns]')\n",
    "# data['Pressure_kpa'] = pressure_kpa['Pressure (kpa)']#.astype('datetime64[ns]')\n",
    "# data['Temperature (C) '] = temperature_Celcius['Temperature (C)']#.astype('datetime64[ns]')\n",
    "# data['Wind Direction (deg)'] = winddirection_degree['Wind Direction (deg)']#.astype('datetime64[ns]')\n",
    "# data['Wind Speed (kmh)'] = windspeed_kmh['Wind Speed (kmh)']#.astype('datetime64[ns]')\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# data = data.append(data_Forecast_Interim).drop(['Humidity (%)'],axis=1)\n",
    "\n",
    "data['day_of_week'] = pd.to_datetime(data.Time).dt.weekday.values\n",
    "data['time_of_day'] = (np.array(range(len(data)))%24)\n",
    "data['is_weekend'] = data.day_of_week.isin([5,6])\n",
    "# data['post_covid'] = data.Time>'2020-03-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rolling_1d'] = data['Load (kW)'].shift(24).rolling(24,center=False).mean()\n",
    "data['rolling_2d'] = data['Load (kW)'].shift(48).rolling(48,center=False).mean()\n",
    "data['rolling_3d'] = data['Load (kW)'].shift(72).rolling(72,center=False).mean()\n",
    "data['rolling_5d'] = data['Load (kW)'].shift(120).rolling(120,center=False).mean()\n",
    "data['rolling_7d'] = data['Load (kW)'].shift(168).rolling(168,center=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Load (kW)'].iloc[-480:].plot()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['2020-10-16 07:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ES model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'statsmodels==0.12.0' --force-reinstall # --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialSmoothing(data['Load (kW)'].values[0:480], seasonal_periods=168, \n",
    "                             trend='add', seasonal='mul', damped_trend=True, use_boxcox=True, initialization_method=\"estimated\").fit()\n",
    "forecast_seasonal_Holt = model.forecast(24)\n",
    "plt.plot(forecast_seasonal_Holt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDay = 28\n",
    "totalDays = 1300\n",
    "samplingFreq = 24\n",
    "minimumTrainDuration = samplingFreq * 13\n",
    "nlags = 360\n",
    "significantLags = 30\n",
    "timeHorizon = 24\n",
    "slidingWindow = True\n",
    "slidingWindowDays = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate PACF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateSignificantLags(ts, nlags = 360, significantLags = 11): \n",
    "    pacf = sm.tsa.stattools.pacf(ts, nlags)\n",
    "    lags = np.argsort(-np.abs(pacf))[1:significantLags+1]\n",
    "    plt.plot(pacf,'*--')\n",
    "    plt.plot(lags,pacf[lags],'o')\n",
    "    return lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = estimateSignificantLags(data['Load (kW)'].dropna(), significantLags = significantLags)\n",
    "# add lags for certain days\n",
    "lags = np.unique(np.hstack([lags,[47,48,49,70,72,94,96,118,120,144]]))\n",
    "print(np.sort(lags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a forecaster with lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_features(df,lags):\n",
    "    tmp = df.copy()\n",
    "    for i in lags:\n",
    "        tmp['lag_'+str(i)] = tmp['Load (kW)'].shift(i)    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_df = add_lag_features(data,lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction(model_name, start_day='2017-04-07', last_known_day='2018-11-07', \n",
    "                      prediction_day='2018-11-08', last_prediction_day='2018-11-09',\n",
    "                      horizon=48):    \n",
    "    \n",
    "    X_train = lags_df.drop(['Load (kW)'], axis=1).loc[start_day:last_known_day]\n",
    "    y_train = lags_df['Load (kW)'].loc[start_day:last_known_day]\n",
    "    #print(X_train,y_train)\n",
    "    model_name.fit(X_train,y_train)\n",
    "\n",
    "    pred_index = pd.date_range(start=prediction_day, periods=horizon, freq='H')\n",
    "    pred_df = pd.DataFrame(index=pred_index, columns=['Load (kW)'])\n",
    "    #print('pred_index',pred_index)\n",
    "    \n",
    "    dataCopy = data.copy()\n",
    "    \n",
    "    for step in pred_index:\n",
    "        \n",
    "        dataCopy = add_lag_features(dataCopy,lags)\n",
    "        #print(dataCopy.loc[step].name)\n",
    "        X_pred = pd.DataFrame(dataCopy.drop(['Load (kW)'], axis=1).loc[step]).T\n",
    "        x_index = dataCopy.loc[step].name\n",
    "        #print(X_pred)\n",
    "        pred_df.loc[x_index] = model_name.predict(X_pred)\n",
    "        \n",
    "        dataCopy.loc[step, 'Load (kW)'] = pred_df.loc[x_index][0]\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a df for all models' outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred = pd.DataFrame(index=data.index, columns=['CB Model'])\n",
    "overall_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prediction for N days: Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(verbose=False,\n",
    "                          learning_rate = 0.01, \n",
    "                          depth=6,\n",
    "                          l2_leaf_reg=4,\n",
    "                          cat_features=['day_of_week','time_of_day','is_weekend']\n",
    "                     )\n",
    "\n",
    "overall_mape = np.zeros(n_days)\n",
    "start_day = pd.to_datetime('2017-12-01 07:00:00')\n",
    "\n",
    "for i in range(n_days):\n",
    "\n",
    "    last_known_day = (start_day + pd.DateOffset(days=30+i))#.date()\n",
    "    prediction_day = (last_known_day + pd.DateOffset(days=1))#.date()\n",
    "    last_prediction_day = str((prediction_day + pd.DateOffset(days=1)))#.date())\n",
    "    print('prediction_day',prediction_day)\n",
    "\n",
    "    pred = create_prediction(model, start_day=start_day, last_known_day=last_known_day, \n",
    "                             prediction_day=prediction_day, last_prediction_day=prediction_day, \n",
    "                             horizon = 41)\n",
    "    \n",
    "    prediction = pred.dropna()['Load (kW)'].values[17:41]\n",
    "    fact = data.loc[pred.dropna().index,'Load (kW)'].values[17:41]\n",
    "\n",
    "    overall_mape[i] = 100 * np.mean(np.abs(prediction - fact)) / np.mean(np.abs(fact))\n",
    "    \n",
    "    overall_pred.loc[pred.index[17:41], 'CB Model'] = pred['Load (kW)'].iloc[17:41]\n",
    "    \n",
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['CB Model'].values, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeHorizon = 48\n",
    "startDay = pd.to_datetime('2017-12-02 07:00:00')\n",
    "\n",
    "for i in range(n_days):\n",
    "\n",
    "    last_known_day = (startDay + pd.DateOffset(days=30+i))\n",
    "    prediction_day = (last_known_day + pd.DateOffset(days=1))\n",
    "    last_prediction_day = str((prediction_day + pd.DateOffset(days=1)))\n",
    "    \n",
    "    print('prediction_day (offset 1d)',prediction_day)\n",
    "    \n",
    "    df = data[['Load (kW)']]\n",
    "    df['ds'] = df.index\n",
    "    df['y'] = df['Load (kW)']\n",
    "    df=df.drop(columns = ['Load (kW)'])\n",
    "    \n",
    "#     df=df.loc[startDay:last_known_day]\n",
    "    df=df.loc[last_known_day-pd.DateOffset(days=30):last_known_day]\n",
    "    \n",
    "#     print(df)\n",
    "    \n",
    "    df['temp'] = (data['Temperature (C) '].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['wind_speed'] = (data['Wind Speed (kmh)'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['cloud'] = (data['Cloud Cover (%)'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['wind_direction'] = (data['Wind Direction (deg)'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['pressure'] = (data['Pressure_kpa'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['day_of_week'] = (data['day_of_week'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['time_of_day'] = (data['time_of_day'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    df['is_weekend'] = (data['is_weekend'].loc[last_known_day-pd.DateOffset(days=30):last_known_day]).values\n",
    "    \n",
    "    m = Prophet(daily_seasonality=40, weekly_seasonality=80, changepoint_prior_scale=0.003, yearly_seasonality=False, seasonality_mode='multiplicative', changepoint_range=.9) #, seasonality_prior_scale=100)\n",
    "#     m = Prophet()\n",
    "    \n",
    "    m.add_regressor('temp')\n",
    "    m.add_regressor('wind_speed')\n",
    "    m.add_regressor('cloud')\n",
    "    m.add_regressor('wind_direction')\n",
    "    m.add_regressor('pressure')\n",
    "    m.add_regressor('day_of_week')\n",
    "    m.add_regressor('time_of_day')\n",
    "    m.add_regressor('is_weekend')\n",
    "    \n",
    "    metrics = m.fit(df)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=timeHorizon, freq='1h')\n",
    "    \n",
    "    future['temp'] = (data['Temperature (C) '].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['wind_speed'] = (data['Wind Speed (kmh)'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['cloud'] = (data['Cloud Cover (%)'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['wind_direction'] = (data['Wind Direction (deg)'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['pressure'] = (data['Pressure_kpa'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['day_of_week'] = (data['day_of_week'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['time_of_day'] = (data['time_of_day'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    future['is_weekend'] = (data['is_weekend'].loc[last_known_day-pd.DateOffset(days=30):last_prediction_day]).values\n",
    "    \n",
    "    #prophetMatrix[i] = m.predict(future).yhat.iloc[-32:-8]\n",
    "    overall_pred.loc[future.ds[-32:-8], 'Prophet_optimized'] = m.predict(future).yhat.iloc[-32:-8].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['Prophet'].values, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prediction for N days: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Pressure_kpa','Temperature (C) ','Cloud Cover (%)','Wind Direction (deg)','Wind Speed (kmh)'],axis=1)\n",
    "lags_df = add_lag_features(data,lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression() # Create a linear model object\n",
    "\n",
    "overall_mape = np.zeros(n_days)\n",
    "start_day = pd.to_datetime('2017-12-01 07:00:00')\n",
    "\n",
    "for i in range(n_days):\n",
    "\n",
    "    last_known_day = (start_day + pd.DateOffset(days=30+i))#.date()\n",
    "    prediction_day = (last_known_day + pd.DateOffset(days=1))#.date()\n",
    "    last_prediction_day = str((prediction_day + pd.DateOffset(days=1)))#.date())\n",
    "    print('prediction_day',prediction_day)\n",
    "\n",
    "    pred = create_prediction(model, start_day=start_day, last_known_day=last_known_day, \n",
    "                             prediction_day=prediction_day, last_prediction_day=prediction_day, \n",
    "                             horizon = 41)\n",
    "    \n",
    "    prediction = pred.dropna()['Load (kW)'].values[17:41]\n",
    "    fact = data.loc[pred.dropna().index,'Load (kW)'].values[17:41]\n",
    "\n",
    "    overall_mape[i] = 100 * np.mean(np.abs(prediction - fact)) / np.mean(np.abs(fact))\n",
    "    \n",
    "    overall_pred.loc[pred.index[17:41], 'LR Model'] = pred['Load (kW)'].iloc[17:41]\n",
    "    \n",
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['LR Model'].values, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make theta prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_theta_prediction(theta_model, start_day, last_known_day, prediction_day, last_prediction_day, horizon):\n",
    "    \n",
    "    series = TimeSeries.from_dataframe(pd.DataFrame(data.loc[start_day:last_prediction_day, 'Load (kW)'])) #TimeSeries.from_dataframe(data.reset_index().iloc[start_time-28*24:start_time+nhorizon], 'Time', 'Load (kW)')        \n",
    "    train, val = series.split_after(pd.Timestamp(last_known_day))\n",
    "    theta_model.fit(train)\n",
    "    return theta_model.predict(horizon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horizon = 41\n",
    "theta_model = Theta(1)\n",
    "start_day = pd.to_datetime('2017-12-01 07:00:00')\n",
    "\n",
    "for i in range(n_days):\n",
    "\n",
    "    last_known_day = (start_day + pd.DateOffset(days=30+i))#.date()\n",
    "    prediction_day = (last_known_day + pd.DateOffset(days=1))#.date()\n",
    "    last_prediction_day = str((prediction_day + pd.DateOffset(days=1)))#.date())\n",
    "    print('prediction_day',prediction_day)\n",
    "    \n",
    "    pred = make_theta_prediction(theta_model,\n",
    "                                   start_day=start_day, \n",
    "                                   last_known_day=last_known_day, \n",
    "                                   prediction_day=prediction_day, \n",
    "                                   last_prediction_day=last_prediction_day, \n",
    "                                   horizon=n_horizon)\n",
    "        \n",
    "    overall_pred.loc[pred.time_index()[16:40], 'Theta Model'] = pred[16:40].values()\n",
    "    \n",
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['Theta Model'].values, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred['LR Model'].dropna()#.plot()#.values[:-40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_prediction = overall_pred['Prophet'].dropna().values[:-40]\n",
    "fact = data.loc[overall_pred['Prophet'].dropna().index,'Load (kW)'].values[:-40]\n",
    "linearNoWeather_prediction = overall_pred['LR Model'].dropna().values[:-40]\n",
    "cb_prediction = overall_pred['CB Model'].dropna().values[:-40]\n",
    "theta_prediction = overall_pred['Theta Model'].dropna().values[:-40]\n",
    "#direct_rf_prediction = overall_pred['Direct RF Model'].dropna().values[:-40]\n",
    "persistence_7d = data.loc[overall_pred['Prophet'].dropna().index + pd.DateOffset(days=-7),'Load (kW)'].values[:-40]\n",
    "#persistence_1d = data.loc[overall_pred.dropna().index + pd.DateOffset(days=-1),'Load (kW)'].values\n",
    "\n",
    "error = prophet_prediction*.225 + cb_prediction*.225 + theta_prediction*.05 + linearNoWeather_prediction*.5 - fact\n",
    "plt.plot(error)\n",
    "plt.show()\n",
    "\n",
    "mape_prophet = 100 * np.mean(np.abs(prophet_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_cb = 100 * np.mean(np.abs(cb_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_lin = 100 * np.mean(np.abs(linearNoWeather_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_theta = 100 * np.mean(np.abs(theta_prediction - fact)) / np.mean(np.abs(fact))\n",
    "#mape_direct_rf = 100 * np.mean(np.abs(direct_rf_prediction - fact)) / np.mean(np.abs(fact))\n",
    "\n",
    "mape_comb_1 = 100 * np.mean(np.abs(prophet_prediction*.5 + .5*cb_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_2 = 100 * np.mean(np.abs(prophet_prediction*.5 + .5*linearNoWeather_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_3 = 100 * np.mean(np.abs(cb_prediction*.5 + .5*linearNoWeather_prediction - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_4 = 100 * np.mean(np.abs(prophet_prediction/5 + cb_prediction/5 + linearNoWeather_prediction*3/5 - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_5 = 100 * np.mean(np.abs(prophet_prediction*.25 + cb_prediction*.25 + theta_prediction*.05 + linearNoWeather_prediction*.45 - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_5m = 100 * np.mean(np.abs(prophet_prediction*.25 + cb_prediction*.25 + theta_prediction*.25 + linearNoWeather_prediction*.25 - fact)) / np.mean(np.abs(fact))\n",
    "mape_comb_5p = 100 * np.mean(np.abs(persistence_7d*.1 + prophet_prediction*.2 + cb_prediction*.2 + theta_prediction*.05 + linearNoWeather_prediction*.45 - fact)) / np.mean(np.abs(fact))\n",
    "mape_persistence_7d = 100 * np.mean(np.abs(persistence_7d - fact)) / np.mean(np.abs(fact))\n",
    "#mape_persistence_1d = 100 * np.mean(np.abs(persistence_1d - fact)) / np.mean(np.abs(fact))\n",
    "\n",
    "mape_comb_6 = 100 * np.mean(np.abs(prophet_prediction*.35 + theta_prediction*.05 + linearNoWeather_prediction*.6 - fact)) / np.mean(np.abs(fact))\n",
    "\n",
    "\n",
    "print('mape Pr:', mape_prophet)\n",
    "print('mape CB:', mape_cb)\n",
    "print('mape Linear:', mape_lin)\n",
    "print('mape Theta:', mape_theta)\n",
    "#print('mape Direct RF:', mape_direct_rf)\n",
    "\n",
    "print('mape comb 1:', mape_comb_1)\n",
    "print('mape comb 2:', mape_comb_2)\n",
    "print('mape comb 3:', mape_comb_3)\n",
    "print('mape comb 4 (all - theta):', mape_comb_4)\n",
    "print('mape comb 5 (all weighted mean):', mape_comb_5)\n",
    "print('mape comb 5 (all weighted mean + persistence):', mape_comb_5p)\n",
    "print('mape comb 5 (all mean):', mape_comb_5m)\n",
    "print('mape comb 6 (no CB):', mape_comb_6)\n",
    "print('mape pers 7d:', mape_persistence_7d)\n",
    "# print('mape pers 1d:', mape_persistence_1d)\n",
    "\n",
    "plt.scatter(prophet_prediction, linearNoWeather_prediction, alpha=0.3)\n",
    "plt.scatter(fact, linearNoWeather_prediction, alpha=0.3)\n",
    "plt.scatter(fact, prophet_prediction, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(sm.tsa.stattools.acf(error,nlags=200), '*--')\n",
    "plt.show()\n",
    "\n",
    "# error2D = (error.reshape((nDays,24))).astype(int)\n",
    "# print(error2D)\n",
    "# plt.imshow(error2D)\n",
    "# plt.show()\n",
    "\n",
    "# plt.boxplot(error2D,1)\n",
    "# plt.plot(range(1,25), np.mean(error2D,0))\n",
    "# plt.show()\n",
    "\n",
    "print(np.corrcoef(prophet_prediction, fact))\n",
    "print(np.corrcoef(linearNoWeather_prediction.astype('float'), fact))\n",
    "print(np.corrcoef(cb_prediction.astype('float'), fact))\n",
    "print(np.corrcoef(theta_prediction, fact))\n",
    "#print(np.corrcoef(direct_rf_prediction, fact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[overall_pred['Prophet'].dropna().index,'Load (kW)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred['naive_weekly'].loc['2018-01-01 00:00:00':'2019-01-01 00:00:00'] = data['Load (kW)'].loc['2017-12-25 00:00:00':'2018-12-25 00:00:00'].values\n",
    "overall_pred['fact'] = data.loc[overall_pred['Prophet'].dropna().index,'Load (kW)']\n",
    "overall_pred['ensemble'] = overall_pred['Prophet']*.25 + overall_pred['CB Model']*.2 + overall_pred['Theta Model']*.05 + overall_pred['LR Model']*.35 + overall_pred['naive_weekly']*.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred.dropna().to_csv('data/district/predictions_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct prediction for residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_X_train = overall_pred.dropna()\n",
    "res_X_train['Final_model']= res_X_train['Prophet']*.3+res_X_train['CB Model']*.2+res_X_train['Theta Model']*.05+res_X_train['LR Model']*.45\n",
    "res_y_train = pd.DataFrame(data.loc[res_X_train.index,'Load (kW)'] - res_X_train['Final_model'], columns=['Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_X_val.shape, res_X_train.shape, res_y_train.shape\n",
    "res_y_train.to_csv('Errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_X_train.join(data[['day_of_week','time_of_day','is_weekend']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_direct_prediction(model_name,start_day='2020-10-15', \n",
    "                             last_known_day='2020-12-16',\n",
    "                             prediction_day='2020-12-17'):    \n",
    "    \n",
    "    #start=time.time()\n",
    "    \n",
    "    y_train = pd.DataFrame(res_y_train.loc[start_day:last_known_day,'Error'])\n",
    "    X_train = pd.DataFrame(res_X_train.loc[start_day:last_known_day,'Final_model'])\n",
    "    \n",
    "    for i in range(16,40):\n",
    "        y_train['error_'+str(i)] = y_train['Error'].shift(-i).astype('float64')\n",
    "        X_train['model_'+str(i)] = X_train['Final_model'].shift(-i).astype('float64')\n",
    "    \n",
    "    y_train = y_train.dropna().drop(['Error'], axis=1)\n",
    "    X_train = X_train.dropna().drop(['Final_model'], axis=1).join(data[['day_of_week','time_of_day','is_weekend']])\n",
    "\n",
    "    #print('y_train',y_train)\n",
    "    #print('X_train',X_train)\n",
    "    \n",
    "    model_name.fit(X_train,y_train)\n",
    "    \n",
    "    step = pd.date_range(start=prediction_day, periods=40, freq='H')\n",
    "\n",
    "    X_pred = pd.DataFrame(res_X_train.loc[step,'Final_model'])\n",
    "    for i in range(16,40):\n",
    "        X_pred['model_'+str(i)] = X_pred['Final_model'].shift(-i).astype('float64')\n",
    "    X_pred = X_pred.dropna().drop(['Final_model'], axis=1).join(data[['day_of_week','time_of_day','is_weekend']])\n",
    "    \n",
    "    prediction = model.predict(X_pred)[0]\n",
    "    #print(X_pred)\n",
    "    #print('Predict: ', time.time()-start)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "#model = MultiOutputRegressor(lgb.LGBMRegressor())\n",
    "\n",
    "#create_direct_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'metric': ['l2', 'auc'],\n",
    "            'learning_rate': 0.005,\n",
    "            \"num_iterations\": 200,\n",
    "            \"n_estimators\": 200}\n",
    "\n",
    "model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n",
    "#model = MultiOutputRegressor(linear_model.LinearRegression())\n",
    "\n",
    "\n",
    "overall_mape = np.zeros(n_days)\n",
    "start_day = pd.to_datetime('2020-11-30 00:00:00')\n",
    "\n",
    "for i in range(n_days):\n",
    "    \n",
    "    last_known_day = (start_day + pd.DateOffset(days=44+i))#.date()\n",
    "    prediction_day = (last_known_day + pd.DateOffset(days=1))#.date()\n",
    "    last_prediction_day = str((prediction_day + pd.DateOffset(days=1)))#.date())\n",
    "    \n",
    "    pred = create_direct_prediction(model, start_day=start_day, last_known_day=last_known_day, \n",
    "                             prediction_day=prediction_day)\n",
    "    \n",
    "    print(prediction_day)\n",
    "    #prediction = pred.dropna()['Load (kW)'].values[17:41]\n",
    "#    fact = data.loc[pred.dropna().index,'Load (kW)'].values[17:41]\n",
    "\n",
    "#    overall_mape[i] = 100 * np.mean(np.abs(prediction - fact)) / np.mean(np.abs(fact))\n",
    "    \n",
    "    overall_pred.loc[str(prediction_day.date()), 'Direct Error Model'] = pred\n",
    "    print(pred)\n",
    "    \n",
    "    #print(overall_pred.loc[str(prediction_day.date())])\n",
    "    \n",
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['Direct Error Model'].values, label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(overall_pred['Direct Error Model'].dropna()[:-16], label='error_pred')\n",
    "plt.plot(res_y_train.loc[overall_pred['Direct Error Model'].dropna().index,'Error'], label='error_fact')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(overall_pred['Direct Error Model'].dropna().values[:-16].astype('float64'),\n",
    "     res_y_train.loc[overall_pred['Direct Error Model'].dropna().index,'Error'].dropna().values.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.loc[overall_pred.dropna().index,'Load (kW)'].values, label='fact')\n",
    "plt.plot(overall_pred.dropna()['CB Model'].values, label='CB Model')\n",
    "plt.plot(overall_pred.dropna()['Prophet'].values, label='Prophet')\n",
    "plt.plot(overall_pred.dropna()['LR Model'].values, label='LR Model')\n",
    "plt.plot(overall_pred.dropna()['Theta Model'].values, label='Theta Model')\n",
    "#plt.plot(overall_pred.dropna()['Direct RF Model'].values, label='Direct RF Model')\n",
    "plt.legend()\n",
    "plt.xlim(800,1300)\n",
    "plt.show()\n",
    "print('mape',overall_mape.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''overall_pred.dropna().iloc[-192:,:].plot()\n",
    "overall_pred.dropna().iloc[-192:,:].mean(axis=1).plot(lw=5)\n",
    "plt.plot(fact,color='red')\n",
    "plt.show()\n",
    "# overall_pred = overall_pred.dropna()\n",
    "\n",
    "plt.plot(prophet_prediction*.25 + cb_prediction*.25 + theta_prediction*.05 + linearNoWeather_prediction*.45,color='black')\n",
    "plt.plot(prophet_prediction,color='black',alpha=0.3)\n",
    "plt.plot(cb_prediction,color='black',alpha=0.3)\n",
    "plt.plot(linearNoWeather_prediction,color='black',alpha=0.3)\n",
    "plt.plot(theta_prediction,color='black',alpha=0.3)\n",
    "plt.plot(fact,color='red')\n",
    "plt.xlim(900,1170)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make single forecast from ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_prediction = overall_pred['Prophet'].dropna().iloc[-24:].values\n",
    "linearNoWeather_prediction = overall_pred['LR Model'].dropna().iloc[-24:].values\n",
    "cb_prediction = overall_pred['CB Model'].dropna().iloc[-24:].values\n",
    "theta_prediction = overall_pred['Theta Model'].dropna().iloc[-24:].values\n",
    "\n",
    "benchmark = data.loc['2021-01-30','Load (kW)'].values\n",
    "\n",
    "final_prediction = prophet_prediction*.2 + cb_prediction*.15 + theta_prediction*.05 + linearNoWeather_prediction*.3+benchmark*.3\n",
    "\n",
    "plt.plot(final_prediction,lw=3)\n",
    "plt.plot(prophet_prediction,label='pr')\n",
    "plt.plot(linearNoWeather_prediction,label='lin')\n",
    "plt.plot(cb_prediction,label='cb')\n",
    "plt.plot(theta_prediction,label='th')\n",
    "plt.plot(benchmark, label='benchmark')\n",
    "plt.legend()\n",
    "\n",
    "np.savetxt('Submitted_Predictions/February-06-Kazmi-Hussain.csv', final_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan19 = pd.read_csv('Submitted_Predictions/February-04-Kazmi-Hussain.csv', header=None)\n",
    "jan19['fact'] = data.loc['2021-02-04','Load (kW)'].values\n",
    "jan19 = jan19.dropna()\n",
    "jan19.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(jan19[0] - jan19['fact']))# / np.mean(np.abs(jan19['fact']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(data['Load (kW)'].loc['2021-01-18':'2021-01-23'].values - data['Load (kW)'].loc['2021-01-11':'2021-01-16'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = data.loc[overall_pred['Prophet'].dropna().index,'Load (kW)'].values[:-40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pred.to_csv('overall_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prophet_prediction = overall_pred['Prophet'].dropna()\n",
    "all_linearNoWeather_prediction = overall_pred['LR Model'].dropna()\n",
    "all_cb_prediction = overall_pred['CB Model'].dropna()\n",
    "all_theta_prediction = overall_pred['Theta Model'].dropna()\n",
    "\n",
    "# all_benchmark = data.loc['2021-01-27','Load (kW)'].values\n",
    "\n",
    "all_final_prediction = all_prophet_prediction*.3 + all_cb_prediction*.25 + all_theta_prediction*.05 + all_linearNoWeather_prediction*.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_final_prediction.iloc[:-40], label='pred')\n",
    "plt.plot(data.loc[all_final_prediction.index[:-40], 'Load (kW)'], label='fact')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_final_prediction.iloc[:-40], data.loc[all_final_prediction.index[:-40], 'Load (kW)'])\n",
    "\n",
    "np.corrcoef(all_final_prediction.iloc[:-40].values.astype('float'), data.loc[all_final_prediction.index[:-40], 'Load (kW)'].values.astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = all_final_prediction.iloc[:-40].values.astype('float') - data.loc[all_final_prediction.index[:-40], 'Load (kW)'].values.astype('float')\n",
    "\n",
    "plt.plot(sm.tsa.stattools.pacf(error, nlags=200),'*--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a mixture of experts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.loc[overall_pred.dropna().index,'Load (kW)'].dropna()\n",
    "X = overall_pred.loc[y.index]\n",
    "\n",
    "X['CB Model'] = X['CB Model'].astype('float')\n",
    "X['LR Model'] = X['LR Model'].astype('float')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_model = lgb.LGBMRegressor()#n_estimators = 2000)\n",
    "mixture_model = linear_model.LinearRegression()\n",
    "mixture_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = mixture_model.predict(X_test)\n",
    "\n",
    "# plt.scatter(y_test, X_test['LR Model'])\n",
    "# plt.scatter(y_test, y_pred)\n",
    "\n",
    "# print(np.corrcoef(y_test, X_test['LR Model']))\n",
    "# print(np.corrcoef(y_test, y_pred))\n",
    "\n",
    "# print(np.mean(np.abs(y_test - X_test['LR Model'])))\n",
    "# print(np.mean(np.abs(y_test - .05*X_test['Theta Model'] -.45*X_test['LR Model'] - .25*X_test['CB Model'] -.25*X_test['Prophet'])))\n",
    "# print(np.mean(np.abs(y_test - y_pred)))\n",
    "\n",
    "# mixture_model.coef_"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m61"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
